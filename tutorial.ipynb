{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Initialize the ChatOllama object\n",
    "llm = ChatOllama(\n",
    "    model = \"llama3.1\",\n",
    "    temperature = 0.8,\n",
    "    num_predict = 256,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here's one:\\n\\nWhy did the woodpecker go to the doctor?\\n\\nBecause it had a screw loose!\\n\\nGet it?\", additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2024-09-19T03:33:46.9678629Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 6433309500, 'load_duration': 29608500, 'prompt_eval_count': 19, 'prompt_eval_duration': 1968544000, 'eval_count': 26, 'eval_duration': 4435548000}, id='run-2145a36d-a967-43c7-979f-73a339370281-0', usage_metadata={'input_tokens': 19, 'output_tokens': 26, 'total_tokens': 45})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"tell me a joke about woodpeckers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='A cat', punchline='Why did the cat join a band? Because it wanted to be the purr-cussionist!', rating=8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "# Pydantic\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "    rating: Optional[int] = Field(\n",
    "        default=None, description=\"How funny the joke is, from 1 to 10\"\n",
    "    )\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "\n",
    "structured_llm.invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'punchline': 'Why did the cat join a band? Because it wanted to be the purr-cussionist!',\n",
       " 'rating': 8,\n",
       " 'setup': 'I just heard that cat can play music'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_schema = {\n",
    "    \"title\": \"joke\",\n",
    "    \"description\": \"Joke to tell user.\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"setup\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The setup of the joke\",\n",
    "        },\n",
    "        \"punchline\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The punchline to the joke\",\n",
    "        },\n",
    "        \"rating\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"How funny the joke is, from 1 to 10\",\n",
    "            \"default\": None,\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"setup\", \"punchline\"],\n",
    "}\n",
    "structured_llm = llm.with_structured_output(json_schema)\n",
    "\n",
    "structured_llm.invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'punchline': 'Why did the cat join a band?', 'rating': 8, 'setup': 'Because it wanted to be the purr-cussionist!'}\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "\n",
    "# TypedDict\n",
    "class Joke(TypedDict):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: Annotated[str, ..., \"The setup of the joke\"]\n",
    "    punchline: Annotated[str, ..., \"The punchline of the joke\"]\n",
    "    rating: Annotated[Optional[int], None, \"How funny the joke is, from 1 to 10\"]\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "\n",
    "for chunk in structured_llm.stream(\"Tell me a joke about cats\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'punchline': 'Because they have a pecking interest in trees!',\n",
       " 'rating': '8',\n",
       " 'setup': 'Why do woodpeckers like trees?'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = \"\"\"You are a hilarious comedian. Your specialty is knock-knock jokes. \\\n",
    "Return a joke which has the setup (the response to \"Who's there?\") and the final punchline (the response to \"<setup> who?\").\n",
    "\n",
    "Here are some examples of jokes:\n",
    "\n",
    "example_user: Tell me a joke about planes\n",
    "example_assistant: {{\"setup\": \"Why don't planes ever get tired?\", \"punchline\": \"Because they have rest wings!\", \"rating\": 2}}\n",
    "\n",
    "example_user: Tell me another joke about planes\n",
    "example_assistant: {{\"setup\": \"Cargo\", \"punchline\": \"Cargo 'vroom vroom', but planes go 'zoom zoom'!\", \"rating\": 10}}\n",
    "\n",
    "example_user: Now about caterpillars\n",
    "example_assistant: {{\"setup\": \"Caterpillar\", \"punchline\": \"Caterpillar really slow, but watch me turn into a butterfly and steal the show!\", \"rating\": 5}}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{input}\")])\n",
    "\n",
    "few_shot_structured_llm = prompt | structured_llm\n",
    "few_shot_structured_llm.invoke(\"what's something funny about woodpeckers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'punchline': 'Because it has a snappy jaw!',\n",
       " 'rating': 8,\n",
       " 'setup': 'Why did the crocodile go to the party?'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "\n",
    "examples = [\n",
    "    HumanMessage(\"Tell me a joke about planes\", name=\"example_user\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"name\": \"joke\",\n",
    "                \"args\": {\n",
    "                    \"setup\": \"Why don't planes ever get tired?\",\n",
    "                    \"punchline\": \"Because they have rest wings!\",\n",
    "                    \"rating\": 2,\n",
    "                },\n",
    "                \"id\": \"1\",\n",
    "            }\n",
    "        ],\n",
    "    ),\n",
    "    # Most tool-calling models expect a ToolMessage(s) to follow an AIMessage with tool calls.\n",
    "    ToolMessage(\"\", tool_call_id=\"1\"),\n",
    "    # Some models also expect an AIMessage to follow any ToolMessages,\n",
    "    # so you may need to add an AIMessage here.\n",
    "    HumanMessage(\"Tell me another joke about planes\", name=\"example_user\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"name\": \"joke\",\n",
    "                \"args\": {\n",
    "                    \"setup\": \"Cargo\",\n",
    "                    \"punchline\": \"Cargo 'vroom vroom', but planes go 'zoom zoom'!\",\n",
    "                    \"rating\": 10,\n",
    "                },\n",
    "                \"id\": \"2\",\n",
    "            }\n",
    "        ],\n",
    "    ),\n",
    "    ToolMessage(\"\", tool_call_id=\"2\"),\n",
    "    HumanMessage(\"Now about caterpillars\", name=\"example_user\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"name\": \"joke\",\n",
    "                \"args\": {\n",
    "                    \"setup\": \"Caterpillar\",\n",
    "                    \"punchline\": \"Caterpillar really slow, but watch me turn into a butterfly and steal the show!\",\n",
    "                    \"rating\": 5,\n",
    "                },\n",
    "                \"id\": \"3\",\n",
    "            }\n",
    "        ],\n",
    "    ),\n",
    "    ToolMessage(\"\", tool_call_id=\"3\"),\n",
    "]\n",
    "system = \"\"\"You are a hilarious comedian. Your specialty is knock-knock jokes. \\\n",
    "Return a joke which has the setup (the response to \"Who's there?\") \\\n",
    "and the final punchline (the response to \"<setup> who?\").\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system), (\"placeholder\", \"{examples}\"), (\"human\", \"{input}\")]\n",
    ")\n",
    "few_shot_structured_llm = prompt | structured_llm\n",
    "few_shot_structured_llm.invoke({\"input\": \"crocodiles\", \"examples\": examples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw': AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2024-09-19T03:56:39.3302123Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'Joke', 'arguments': {'punchline': 'Why did the cat join a band? Because it wanted to be the purr-cussionist!', 'rating': 8, 'setup': 'Why did the cat join a band?'}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 13178793500, 'load_duration': 2160804200, 'prompt_eval_count': 206, 'prompt_eval_duration': 523082000, 'eval_count': 56, 'eval_duration': 10493172000}, id='run-9fdc170a-b2a7-4aa7-a434-8b91816ab0e9-0', tool_calls=[{'name': 'Joke', 'args': {'punchline': 'Why did the cat join a band? Because it wanted to be the purr-cussionist!', 'rating': 8, 'setup': 'Why did the cat join a band?'}, 'id': '5fce4045-0555-4a94-b14d-61ffeabb6636', 'type': 'tool_call'}], usage_metadata={'input_tokens': 206, 'output_tokens': 56, 'total_tokens': 262}),\n",
       " 'parsed': {'punchline': 'Why did the cat join a band? Because it wanted to be the purr-cussionist!',\n",
       "  'rating': 8,\n",
       "  'setup': 'Why did the cat join a band?'},\n",
       " 'parsing_error': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm = llm.with_structured_output(Joke, include_raw=True)\n",
    "\n",
    "structured_llm.invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Diana\\OneDrive\\Documents\\ingridientsGPT\\venv\\Lib\\site-packages\\pydantic\\json_schema.py:2191: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The initial part of the joke that sets the scene or asks a question. It should end with a question mark.' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "c:\\Users\\Diana\\OneDrive\\Documents\\ingridientsGPT\\venv\\Lib\\site-packages\\pydantic\\json_schema.py:2191: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The final part of the joke that delivers the humor or surprise. It should be concise and related to the setup.' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup='Why do programmers prefer dark mode?' punchline='Because light attracts bugs.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.pydantic_v1 import  Field, validator\n",
    "from pydantic import BaseModel\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.output_parsers import  PydanticOutputParser\n",
    "\n",
    "# Initialize the ChatOllama object\n",
    "llm = ChatOllama(\n",
    "    model = \"llama3.1\",\n",
    "    temperature = 0,\n",
    ")\n",
    "\n",
    "# Define your desired data structure with improved descriptions\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"The initial part of the joke that sets the scene or asks a question. It should end with a question mark.\")\n",
    "    punchline: str = Field(description=\"The final part of the joke that delivers the humor or surprise. It should be concise and related to the setup.\")\n",
    "\n",
    "    @validator(\"setup\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Setup must end with a question mark!\")\n",
    "        return field\n",
    "\n",
    "\n",
    "# Set up the parser\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt_template = \"\"\"You are a witty comedian tasked with creating a short, funny joke.\n",
    "\n",
    "Instructions:\n",
    "1. Create a joke with a setup (question) and a punchline (answer).\n",
    "2. The setup should end with a question mark.\n",
    "3. The punchline should be clever and related to the setup.\n",
    "4. Keep both parts concise and clear.\n",
    "\n",
    "Format your response according to these instructions:\n",
    "{format_instructions}\n",
    "\n",
    "Now, please generate a joke based on this query: {query}\n",
    "\"\"\"\n",
    "\n",
    "# Improved prompt template\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Create the chain\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# Query for a joke\n",
    "joke_query = \"Tell me a joke about programming.\"\n",
    "result = chain.invoke({\"query\": joke_query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup='Why did the cat join a band?' punchline='Because it wanted to be the purr-cussionist!'\n",
      "setup='Why did Simba and Leo go to the vet?' punchline='Because they were having cat-astrophic health issues!'\n"
     ]
    }
   ],
   "source": [
    "another_query = \"Tell me a joke about cats.\"\n",
    "result = chain.invoke({\"query\": another_query})\n",
    "print(result)\n",
    "\n",
    "another_query = \"Tell me a joke about simba and leo 2 cats.\"\n",
    "result = chain.invoke({\"query\": another_query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
